{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS, cross_origin\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_model = tf.keras.models.load_model(\"./fraud_model/\")\n",
    "\n",
    "df_test = pd.read_csv('medical_insurance_fraud_test.csv', index_col=0)\n",
    "\n",
    "def bucketize(val, size, count):\n",
    "    i=0\n",
    "    for i in range(count):\n",
    "        if val <= (i+1)*size:\n",
    "            return i\n",
    "    return i\n",
    "\n",
    "def bucketize_df(df):\n",
    "    df['Age_group'] = [bucketize(x, 10, 5) for x in df['Age']]\n",
    "    df['BMI_group'] = [bucketize(x, 10, 5) for x in df['BMI']]\n",
    "    df.drop(['Age'], axis=1, inplace=True)\n",
    "    df.drop(['BMI'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_test = bucketize_df(df_test)\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    df = pd.concat([df,pd.get_dummies(df['Age_group'], prefix='Age')],axis=1)\n",
    "    df = pd.concat([df,pd.get_dummies(df['BMI_group'], prefix='BMI')],axis=1)\n",
    "    df.drop(['Age_group'], axis=1, inplace=True)\n",
    "    df.drop(['BMI_group'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_test = one_hot_encode(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    30000\n",
       "1.0      300\n",
       "Name: Fraud, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_test['Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30300.000000\n",
       "mean     16526.867915\n",
       "std      10337.683697\n",
       "min       2253.404003\n",
       "25%       7626.555685\n",
       "50%      12943.563178\n",
       "75%      25986.360584\n",
       "max      80337.557453\n",
       "Name: Cost, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.Cost.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "testDataX = df_test.copy().drop(['Fraud'],axis=1)\n",
    "testDataY = df_test['Fraud'].copy()\n",
    "\n",
    "sX = pp.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "featuresToScale = testDataX.columns\n",
    "testDataX.loc[:,featuresToScale] = sX.fit_transform(testDataX[featuresToScale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyScores(originalDF, reducedDF):\n",
    "    loss = np.sum((np.array(originalDF) - \\\n",
    "                   np.array(reducedDF))**2, axis=1)\n",
    "    loss = pd.Series(data=loss,index=originalDF.index)\n",
    "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
    "    \n",
    "    print('Mean for anomaly scores: ', np.mean(loss))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0523 14:57:05.064521 140157617170240 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30300/30300 [==============================] - 1s 26us/sample\n",
      "Mean for anomaly scores:  0.0033387805516674014\n"
     ]
    }
   ],
   "source": [
    "predictions = imported_model.predict(testDataX, verbose=1)\n",
    "anomalyScoresAE = anomalyScores(testDataX, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/katana-ml/api/v1.0/fraud/process\", methods=['POST'])\n",
    "def process():\n",
    "    fraud_threshold = request.json['fraud_threshold']\n",
    "    \n",
    "    testDataCost = df_test['Cost'].copy()\n",
    "    df_preds = pd.concat([testDataCost, testDataY, anomalyScoresAE], axis=1)\n",
    "    df_preds.columns = ['Cost', 'Fraud', 'AnomalyScore']\n",
    "\n",
    "    conditions = [\n",
    "        (df_preds['Fraud'] == 1) & (df_preds['AnomalyScore'] >= fraud_threshold),\n",
    "        (df_preds['Fraud'] == 0) & (df_preds['AnomalyScore'] >= fraud_threshold),\n",
    "        (df_preds['Fraud'] == 1) & (df_preds['AnomalyScore'] < fraud_threshold)]\n",
    "    choices = [1, 2, 3]\n",
    "\n",
    "    df_preds['FraudPredict'] = np.select(conditions, choices, default=0)\n",
    "    \n",
    "    outliers = pd.DataFrame()\n",
    "    outliers['transaction_id'] = df_preds.index.values\n",
    "    outliers['fraud_predict'] = df_preds['FraudPredict']\n",
    "    outliers['claim_cost'] = df_preds['Cost']\n",
    "    \n",
    "    outliers_non_fraud = outliers.loc[outliers['fraud_predict'] == 0]\n",
    "    claim_cost_max = outliers_non_fraud['claim_cost'].max()\n",
    "    \n",
    "    outliers_fraud = outliers.loc[outliers['fraud_predict'] != 0]\n",
    "    outliers_fraud['non_fraud_cost_max'] = claim_cost_max\n",
    "    \n",
    "    result = outliers_fraud.to_json(orient='records', date_format='iso')\n",
    "    return result\n",
    "\n",
    "@app.route(\"/katana-ml/api/v1.0/fraud/stats\", methods=['POST'])\n",
    "def fraud_stats():\n",
    "    fraud_threshold = request.json['fraud_threshold']\n",
    "    \n",
    "    testDataCost = df_test['Cost'].copy()\n",
    "    df_preds = pd.concat([testDataCost, testDataY, anomalyScoresAE], axis=1)\n",
    "    df_preds.columns = ['Cost', 'Fraud', 'AnomalyScore']\n",
    "\n",
    "    conditions = [\n",
    "        (df_preds['Fraud'] == 1) & (df_preds['AnomalyScore'] >= fraud_threshold),\n",
    "        (df_preds['Fraud'] == 0) & (df_preds['AnomalyScore'] >= fraud_threshold),\n",
    "        (df_preds['Fraud'] == 1) & (df_preds['AnomalyScore'] < fraud_threshold)]\n",
    "    choices = [1, 2, 3]\n",
    "\n",
    "    df_preds['FraudPredict'] = np.select(conditions, choices, default=0)\n",
    "    df_value_counts = pd.value_counts(df_preds['FraudPredict'])\n",
    "    \n",
    "    df_value_counts = df_value_counts.reset_index()\n",
    "    df_value_counts.columns = ['unique_values', 'counts']\n",
    "    \n",
    "    return df_value_counts.to_json(orient='records', date_format='iso')\n",
    "\n",
    "# running REST interface\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
